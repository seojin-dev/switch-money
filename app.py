import streamlit as st
from prophet import Prophet
import pandas as pd
import matplotlib.pyplot as plt
from datetime import timedelta, date, datetime
import openai
import platform
from matplotlib import font_manager, rc
from dotenv import load_dotenv
import os
import requests
import plotly.graph_objects as go

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
api_key = os.getenv("KOREA_EXIM_API_KEY")
news_api_key = os.getenv("NEWS_API_KEY")  # NewsAPI í‚¤ë„ .envì— ì¶”ê°€ í•„ìš”

def set_korean_font():
    try:
        font_path = os.path.join("fonts", "NanumGothicCoding.ttf")
        if not os.path.exists(font_path):
            raise FileNotFoundError("NanumGothicCoding.ttf not found")
        font_name = font_manager.FontProperties(fname=font_path).get_name()
        font_manager.fontManager.addfont(font_path)
        rc('font', family=font_name)
        plt.rcParams['axes.unicode_minus'] = False
        print(f"[LOG] í•œê¸€ í°íŠ¸ ì ìš©ë¨: {font_name}")
    except Exception as e:
        print(f"[WARN] í•œê¸€ í°íŠ¸ ì ìš© ì‹¤íŒ¨: {e}")

set_korean_font()

# í™˜ìœ¨ ë°ì´í„° ì „ì²˜ë¦¬
print("[LOG] Loading and preprocessing data...")
df = pd.read_csv("switch.csv")
df['ë‚ ì§œ'] = pd.to_datetime(df['ë³€í™˜'], format='%Y/%m/%d', errors='coerce')
df['í™˜ìœ¨'] = df['ì›ìë£Œ'].str.replace(',', '').astype(float)
df = df[['ë‚ ì§œ', 'í™˜ìœ¨']].dropna().sort_values('ë‚ ì§œ')
df = df.rename(columns={'ë‚ ì§œ': 'ds', 'í™˜ìœ¨': 'y'})

# API í™˜ìœ¨ ë°ì´í„° ì¶”ê°€
def fetch_korea_exim_rates(start_date, end_date, auth_key):
    url = f"https://www.koreaexim.go.kr/site/program/financial/exchangeJSON?authkey={auth_key}&searchdate={{}}&data=AP01"
    records = []
    current = pd.to_datetime(start_date)
    end = pd.to_datetime(end_date)
    while current <= end:
        formatted = current.strftime("%Y%m%d")
        try:
            res = requests.get(url.format(formatted))
            data = res.json()
            for item in data:
                if item['cur_unit'] == 'USD':
                    records.append({"ds": current, "y": float(item['deal_bas_r'].replace(',', ''))})
                    break
        except Exception as e:
            print(f"[WARN] Failed to fetch for {formatted}: {e}")
        current += timedelta(days=1)
    return pd.DataFrame(records)

api_df = fetch_korea_exim_rates("2025-05-03", date.today(), api_key)
df = pd.concat([df, api_df]).drop_duplicates(subset="ds").sort_values("ds")

model = Prophet()
model.fit(df)

latest_date = df['ds'].max()

# Streamlit UI
st.markdown("""
    <h1 style='text-align: center;'>
        ğŸ’± AI FxSense(AIí™˜ìœ¨ì˜ˆì¸¡ì‹œìŠ¤í…œ)<br>
        <span style='font-size: 0.5em;'>SWitch Money íŒ€ â€” ì„œìš¸êµìœ¡ëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´ì˜ì¬êµìœ¡ì›</span><br>
        <span style='font-size: 0.5em;'>ê¹€ì„œì§„, ê¹€ìš°í˜„, ë°•ì¬ë¯¼</span>
    </h1>
""", unsafe_allow_html=True)

if st.button("ì´ˆê¸°í™”"):
    st.session_state.clear()
    st.rerun()

st.markdown("<p style='text-align: center;'>ê¸°ì‚¬ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:</p>", unsafe_allow_html=True)
article_text = st.text_area("ê¸°ì‚¬ ì…ë ¥", label_visibility="collapsed", height=150)
days = st.number_input("ê·¸ë˜í”„ì— í‘œì‹œí•  ë¯¸ë˜ ì¼ìˆ˜", min_value=1, max_value=3650, value=30, step=1)
sensitivity = st.slider("ê°ì„± ë³´ì • ê°•ë„", min_value=0.0, max_value=1.0, value=0.3, step=0.1)

def analyze_article_sentiment(article):
    prompt = f"""
    ì•„ë˜ ê¸°ì‚¬ê°€ ì›/ë‹¬ëŸ¬ í™˜ìœ¨ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ íŒë‹¨í•´ì¤˜.
    'ê¸ì •ì ', 'ë¶€ì •ì ', 'ì¤‘ë¦½ì ' ì¤‘ í•˜ë‚˜ë¡œ ì‘ë‹µí•˜ê³  ê°„ë‹¨í•œ ì´ìœ ë„ ì„¤ëª…í•´ì¤˜.
    ê¸°ì‚¬:
    {article}
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"[ERROR] ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}"

if st.button("í™˜ìœ¨ ì˜ˆì¸¡ ì‹¤í–‰"):
    if 'predicted' not in st.session_state:
        st.session_state['predicted'] = True
        future = model.make_future_dataframe(periods=days)
        forecast = model.predict(future)
        next_day = date.today() + timedelta(days=1)
        next_pred = forecast[forecast['ds'] == pd.to_datetime(next_day)]['yhat'].values
        adj = 0.0
        if article_text.strip():
            st.subheader("AI ê°ì„± ë¶„ì„ ê²°ê³¼")
            sentiment_result = analyze_article_sentiment(article_text)
            st.write(sentiment_result)
            if "ê¸ì •" in sentiment_result:
                adj = -sensitivity / 100
            elif "ë¶€ì •" in sentiment_result:
                adj = sensitivity / 100
        if len(next_pred) > 0:
            raw = next_pred[0]
            adj_val = raw * (1 + adj)
            st.success(f"ì˜ˆì¸¡ í™˜ìœ¨: {raw:.2f}â‚© (ê°ì„± ë³´ì •: {adj_val:.2f}â‚©)")
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.plot(df['ds'], df['y'], label='ì‹¤ì œ í™˜ìœ¨', color='black')
        ax.plot(forecast['ds'], forecast['yhat'], label='ì˜ˆì¸¡ í™˜ìœ¨', color='blue')
        ax.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], color='lightblue', alpha=0.4)
        ax.axvline(x=latest_date, color='gray', linestyle='--')
        ax.set_xlim([latest_date - timedelta(days=100), forecast['ds'].max()])
        ax.set_ylim(0, 2000)
        st.pyplot(fig)
        st.download_button("ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)", forecast.to_csv(index=False).encode('utf-8-sig'), "í™˜ìœ¨_ì˜ˆì¸¡.csv")

# ğŸ“Œ ê³¼ê±° ì „ì²´ ì‹œê³„ì—´ ë° ê¸°ì‚¬ ê²€ìƒ‰ ê¸°ëŠ¥
st.subheader("ê³¼ê±° ì „ì²´ í™˜ìœ¨ ê·¸ë˜í”„")
fig2 = go.Figure()
fig2.add_trace(go.Scatter(x=df['ds'], y=df['y'], mode='lines+markers', name='í™˜ìœ¨'))
fig2.update_layout(title="ì „ì²´ í™˜ìœ¨ ì¶”ì´", xaxis_title="ë‚ ì§œ", yaxis_title="â‚©", hovermode='x unified')
st.plotly_chart(fig2, use_container_width=True)

selected_date = st.date_input("ê¸°ì‚¬ë¥¼ ë³´ê³  ì‹¶ì€ ë‚ ì§œ ì„ íƒ", value=date.today())

def fetch_news_for_date(target_date):
    query = f"í™˜ìœ¨+OR+ê²½ì œ+OR+ë¬´ì—­+OR+ê¸ˆë¦¬"
    url = f"https://newsapi.org/v2/everything?q={query}&from={target_date}&to={target_date}&language=ko&sortBy=relevancy&apiKey={news_api_key}"
    try:
        res = requests.get(url)
        articles = res.json().get('articles', [])[:10]
        return [{"title": a['title'], "url": a['url']} for a in articles]
    except Exception as e:
        return [
            {"title": f"ë‰´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}", "url": "#"}
        ]

if st.button("ì„ íƒí•œ ë‚ ì§œ ê¸°ì‚¬ ë³´ê¸°"):
    news_list = fetch_news_for_date(selected_date)
    st.subheader(f"{selected_date} ì£¼ìš” ë‰´ìŠ¤")
    for i, news in enumerate(news_list):
        st.markdown(f"{i+1}. [{news['title']}]({news['url']})")

st.markdown("""
<div style='text-align: center; margin-top: 2em;'>
    <a href='https://ember-ski-cec.notion.site/AI-SWitch-Money-204d0abe582680349dd5e39320e73eaf?source=copy_link'
       target='_blank'
       style='text-decoration: none; font-size: 1.1em; color: #2d79c7; font-weight: 600;'>
        ğŸ“˜ ìì„¸í•œ ì„¤ëª… ë³´ëŸ¬ê°€ê¸° (Notion)
    </a>
</div>
""", unsafe_allow_html=True)
